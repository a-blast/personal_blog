<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Optimal Digression</title>
    <link>/post/</link>
    <description>Recent content in Posts on Optimal Digression</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Define your motivation, do your research (&amp; eat your vegetables).</title>
      <link>/post/define-your-motivation-do-your-research-eat-your-vegetables/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/define-your-motivation-do-your-research-eat-your-vegetables/</guid>
      <description>So you want to build a data product. Before you even try to touch your favorite text editor (hopefully Spacemacs üëΩ), you‚Äôve got some work to do. Back when I worked in a biochemistry lab, and an experiment failed, my PI would always point out that often times spending a day in the library can save weeks in the lab (and a fat stack of money). This axiom sits true in any field where there is something worth doing.</description>
    </item>
    
    <item>
      <title>Build a data feature that matters.</title>
      <link>/post/build-something-that-matters-in-r/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/build-something-that-matters-in-r/</guid>
      <description>The most important skill of any aspiring data professional is the abillity to make kick butt, automated data features (and ultimately, products).
This fact has given rise to what I‚Äôll dub here as the ‚Äúfull stack‚Äù data scientist. A full stack data scientist is someone comfortable with building the entire data product ‚Äúcircuit‚Äù him/herself. At a high level, this entails a command of comfort in building data pipelines, synthesizing readable code-bases, employing relevant statistical/machine learning paradigms, and interacting with an appropriate database that can empower the delivery of value that you ultimately want to produce.</description>
    </item>
    
  </channel>
</rss>